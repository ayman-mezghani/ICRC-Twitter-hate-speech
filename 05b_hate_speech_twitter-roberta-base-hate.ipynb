{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fa3a88-cca5-41c1-b1df-4a4c1aec496f",
   "metadata": {},
   "source": [
    "# Hate Speech Detection B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88329acf-75b2-4b37-a633-ecee65b22992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mezghani/miniconda3/envs/lsir/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=4, progress_bar=False)\n",
    "\n",
    "import torch\n",
    "\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede54216-c42f-4e94-835e-40b79de0e3d8",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6aa82e-5502-4cdd-b479-cb74aea7d9e9",
   "metadata": {},
   "source": [
    "### Load Tokenizer and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbbc523-257d-4012-9b98-f4a25bdfef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-hate')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-hate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd509e5a-c93f-43f3-bd62-f4e2238cc047",
   "metadata": {},
   "source": [
    "### Load Model Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c490078-877f-4e47-a62c-0e51335a7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_link = f'https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/mapping.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e721cd07-04b4-45e7-86e9-2f929ed30591",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(mapping_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8448afdd-4718-4093-9491-1a1c4e2cfa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {i: s.split('\\t')[1] for i, s in enumerate(response.content.decode('utf-8').split('\\n'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6485c3a2-e99d-456f-8c5b-40c1c7519854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'not-hate', 1: 'hate'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9fa18-0f61-4e7d-9cde-0a3d7cfed2b3",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf3019-dd58-4170-810d-278c5baa05b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22257c8f-2f11-4b54-b9c2-cb8b3eace85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_parquet('data/tweets/en/english_tweets.parquet')\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c4709-bf22-4bc2-a226-1b2d5e1536e1",
   "metadata": {},
   "source": [
    "### Load News IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a507433-d6b8-4057-b892-6a0dc65c4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_ids = pd.read_csv('data/news/news_indexes.csv', header=None).values.reshape(-1)\n",
    "news_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddb4a5-510d-4828-8f7d-e214c9e0fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2cdfc-cd13-43dd-abbb-60183d875d38",
   "metadata": {},
   "source": [
    "### Filter News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410afbe6-90fa-4c7a-a665-c3fbd2152f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['id'] = df_tweets['id'].astype(int)\n",
    "df_tweets['is_news'] = df_tweets['id'].isin(news_ids)\n",
    "df_tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7308853d-0fc4-406b-bf37-9fa02e9aee8e",
   "metadata": {},
   "source": [
    "## Hate Speech Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35982901-41be-435a-ad6f-c577ab6dea5c",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4d757-8312-4f46-a00a-658c3fcb2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(' '):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec3816-122f-4aec-be1e-3e98c9c3f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['pre_process_text'] = df_tweets.text.str.replace(r'\\s+', ' ', regex=True).parallel_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbd83e-4a2b-44bc-b790-77989a592a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_tweets.pre_process_text.values.tolist()\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ebf4de-445b-4f4f-86b4-92cb3b58f4ae",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a20d8-c6fe-46e3-b0aa-2d2ea28ca93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183a70e-545f-4225-a23a-2cd3e00e4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6196598-0ccd-4c5a-ba40-053e40fd71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dccb99-20b3-4d75-8e4a-8df8d7c90031",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 50\n",
    "res = []\n",
    "\n",
    "for i in tqdm(list(range(0, len(df_tweets), step))):\n",
    "    j = min(i+step, len(df_tweets))\n",
    "    print(i, j, len(df_tweets))\n",
    "    \n",
    "    _texts = texts[i:j]\n",
    "    \n",
    "    ### Tokenizing\n",
    "\n",
    "    encoded_input = tokenizer(_texts, return_tensors='pt', padding=True).to(device)\n",
    "\n",
    "    ### Hate Speech Classification\n",
    "\n",
    "    output = model(**encoded_input)\n",
    "\n",
    "    scores = softmax(output[0].detach().cpu().numpy(), axis=1)\n",
    "    \n",
    "    res.append(scores)\n",
    "    \n",
    "    del encoded_input\n",
    "    del output\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de134b9-4058-4a9f-91c2-f2fc9b8413e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores = pd.DataFrame(np.concatenate(res, axis=0), index=sample.index).rename(columns=id2label)['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a739994-f060-43bf-8ece-c698eb38ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['hate_speech_b'] = result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e1ae8-4301-4749-9f65-cb4f482cca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[['id', 'hate_speech_b']].to_parquet('data/hate_speech/hate_model_b.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4036b1-3d67-4897-960d-64d58f52556d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
